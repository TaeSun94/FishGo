{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ref site: https://medium.com/edit-name/imageai-image-%EC%9D%B8%EC%8B%9D%EC%9D%84-%EB%AA%87-%EC%A4%84%EC%9D%98-%EC%BD%94%EB%93%9C%EB%A1%9C-%ED%95%A0-%EC%88%98-%EC%9E%88%EB%8B%A8%EB%8B%A4-95ee9edc17ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==1.15 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (1.15.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.19.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (3.13.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (3.3.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (0.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.0.8)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (0.35.1)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.15.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.33.2)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorflow==1.15) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow==1.15) (50.3.0.post20201006)\n",
      "Requirement already satisfied: h5py in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (1.19.3)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: scipy in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from scipy) (1.19.3)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: opencv-python in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (4.4.0.44)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from opencv-python) (1.19.3)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: pillow in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (8.0.1)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from matplotlib) (1.19.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from matplotlib) (8.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: h5py in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (2.10.0)\n",
      "Requirement already satisfied: six in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from h5py) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from h5py) (1.19.3)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: keras in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from keras) (1.19.3)\n",
      "Requirement already satisfied: h5py in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from keras) (1.5.3)\n",
      "Requirement already satisfied: six in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from h5py->keras) (1.15.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n",
      "Requirement already satisfied: requests in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (from requests) (1.25.11)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy \n",
    "!pip3 install scipy \n",
    "!pip3 install opencv-python \n",
    "!pip3 install pillow \n",
    "!pip3 install matplotlib \n",
    "!pip3 install h5py \n",
    "!pip3 install keras\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageai==2.0.2 from https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl in /home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages (2.0.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for lxml: [Errno 2] No such file or directory: '/home/team2/anaconda3/envs/pjt3/lib/python3.6/site-packages/lxml-4.6.1.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.2/imageai-2.0.2-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import requests\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from imageai.Prediction.Custom import ModelTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 112, 112, 64) 9472        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 112, 112, 64) 256         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 112, 112, 64) 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 55, 55, 64)   256         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 55, 55, 64)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 55, 55, 64)   36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 55, 55, 64)   256         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 55, 55, 64)   0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 55, 55, 256)  16640       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 55, 55, 256)  1024        conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 55, 55, 256)  1024        conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 55, 55, 256)  0           batch_normalization_57[0][0]     \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 55, 55, 256)  0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 55, 55, 64)   16448       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 55, 55, 64)   256         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 55, 55, 64)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 55, 55, 64)   36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 55, 55, 64)   256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 55, 55, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 55, 55, 256)  16640       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 55, 55, 256)  1024        conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 55, 55, 256)  0           batch_normalization_60[0][0]     \n",
      "                                                                 activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 55, 55, 256)  0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 55, 55, 64)   16448       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 55, 55, 64)   256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 55, 55, 64)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 55, 55, 64)   36928       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 55, 55, 64)   256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 55, 55, 64)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 55, 55, 256)  16640       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 55, 55, 256)  1024        conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 55, 55, 256)  0           batch_normalization_63[0][0]     \n",
      "                                                                 activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 55, 55, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 28, 28, 128)  32896       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 28, 28, 128)  512         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 28, 28, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 28, 28, 128)  147584      activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 28, 28, 128)  512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 28, 28, 128)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 28, 28, 512)  66048       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 28, 28, 512)  131584      activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 28, 28, 512)  2048        conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 28, 28, 512)  2048        conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 28, 28, 512)  0           batch_normalization_67[0][0]     \n",
      "                                                                 batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 28, 28, 512)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 28, 28, 128)  65664       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 28, 28, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 28, 28, 128)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 28, 28, 128)  147584      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 28, 28, 128)  512         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 28, 28, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 28, 28, 512)  66048       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 28, 28, 512)  2048        conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 512)  0           batch_normalization_70[0][0]     \n",
      "                                                                 activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 28, 28, 512)  0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 28, 28, 128)  65664       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 28, 28, 128)  512         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 28, 28, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 28, 28, 128)  147584      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 28, 28, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 28, 28, 128)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 28, 28, 512)  66048       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 28, 28, 512)  2048        conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 28, 28, 512)  0           batch_normalization_73[0][0]     \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 28, 28, 512)  0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 28, 28, 128)  65664       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 28, 28, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 28, 28, 128)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 28, 28, 128)  147584      activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 28, 28, 128)  512         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 28, 28, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 28, 28, 512)  66048       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 28, 28, 512)  2048        conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 28, 28, 512)  0           batch_normalization_76[0][0]     \n",
      "                                                                 activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 28, 28, 512)  0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 256)  131328      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 14, 14, 256)  1024        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 256)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 256)  590080      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 256)  1024        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 256)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 14, 14, 1024) 263168      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 14, 14, 1024) 525312      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 1024) 4096        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 14, 14, 1024) 4096        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_80[0][0]     \n",
      "                                                                 batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 1024) 0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 14, 14, 256)  262400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 14, 14, 256)  1024        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 256)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 14, 14, 256)  590080      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 14, 14, 256)  1024        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 256)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 14, 14, 1024) 263168      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 14, 14, 1024) 4096        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_83[0][0]     \n",
      "                                                                 activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 1024) 0           add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 256)  262400      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 14, 14, 256)  1024        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 256)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 256)  590080      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 256)  1024        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 256)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 14, 14, 1024) 263168      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 1024) 4096        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_86[0][0]     \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 1024) 0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 14, 14, 256)  262400      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 14, 14, 256)  1024        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 14, 14, 256)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 14, 14, 256)  590080      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 14, 14, 256)  1024        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 256)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 14, 14, 1024) 263168      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 14, 14, 1024) 4096        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_89[0][0]     \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 1024) 0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 14, 14, 256)  262400      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 14, 14, 256)  1024        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 256)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 14, 14, 256)  590080      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 14, 14, 256)  1024        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 256)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 14, 14, 1024) 263168      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 14, 14, 1024) 4096        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_92[0][0]     \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 1024) 0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 14, 14, 256)  262400      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 14, 14, 256)  1024        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 256)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 14, 14, 256)  590080      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 14, 14, 256)  1024        conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 256)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 14, 14, 1024) 263168      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 14, 14, 1024) 4096        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_95[0][0]     \n",
      "                                                                 activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 14, 14, 1024) 0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 7, 512)    524800      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 7, 512)    2048        conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 512)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 7, 512)    2359808     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 7, 512)    2048        conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 512)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 7, 2048)   8192        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 7, 2048)   8192        conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_99[0][0]     \n",
      "                                                                 batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 2048)   0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 7, 512)    1049088     activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 7, 512)    2048        conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 512)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 7, 512)    2359808     activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 7, 512)    2048        conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 512)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 7, 2048)   8192        conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_102[0][0]    \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 2048)   0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 7, 512)    1049088     activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 7, 512)    2048        conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 512)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 7, 512)    2359808     activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 7, 512)    2048        conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 512)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 7, 2048)   8192        conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_105[0][0]    \n",
      "                                                                 activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 2048)   0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_avg_pooling (GlobalAvera (None, 2048)         0           activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 21)           43029       global_avg_pooling[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 21)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,630,741\n",
      "Trainable params: 23,577,621\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Enhanced Data Generation\n",
      "Found 1081 images belonging to 21 classes.\n",
      "Found 269 images belonging to 21 classes.\n",
      "JSON Mapping for the model classes saved to  /home/team2/fishgo/training/json/model_class.json\n",
      "Number of experiments (Epochs) :  200\n",
      "Epoch 1/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 3.6222 - acc: 0.1263Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 15s - loss: 3.5299 - acc: 0.0692\n",
      "Epoch 00001: saving model to /home/team2/fishgo/training/models/model_ex-001_acc-0.069231.h5\n",
      "108/108 [==============================] - 140s 1s/step - loss: 3.6131 - acc: 0.1261 - val_loss: 3.5299 - val_acc: 0.0692\n",
      "Epoch 2/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 3.0016 - acc: 0.1367Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 120.9135 - acc: 0.0577\n",
      "Epoch 00002: saving model to /home/team2/fishgo/training/models/model_ex-002_acc-0.057692.h5\n",
      "108/108 [==============================] - 80s 743ms/step - loss: 3.0067 - acc: 0.1373 - val_loss: 120.9135 - val_acc: 0.0577\n",
      "Epoch 3/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.8937 - acc: 0.1546Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.2665 - acc: 0.1577\n",
      "Epoch 00003: saving model to /home/team2/fishgo/training/models/model_ex-003_acc-0.157692.h5\n",
      "108/108 [==============================] - 80s 743ms/step - loss: 2.8986 - acc: 0.1541 - val_loss: 3.2665 - val_acc: 0.1577\n",
      "Epoch 4/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.7518 - acc: 0.1725Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 67.9010 - acc: 0.0808\n",
      "Epoch 00004: saving model to /home/team2/fishgo/training/models/model_ex-004_acc-0.080769.h5\n",
      "108/108 [==============================] - 80s 739ms/step - loss: 2.7558 - acc: 0.1727 - val_loss: 67.9010 - val_acc: 0.0808\n",
      "Epoch 5/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.6662 - acc: 0.1748Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 5.4479 - acc: 0.0923\n",
      "Epoch 00005: saving model to /home/team2/fishgo/training/models/model_ex-005_acc-0.092308.h5\n",
      "108/108 [==============================] - 81s 746ms/step - loss: 2.6642 - acc: 0.1750 - val_loss: 5.4479 - val_acc: 0.0923\n",
      "Epoch 6/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.5400 - acc: 0.2025Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.1066 - acc: 0.0923\n",
      "Epoch 00006: saving model to /home/team2/fishgo/training/models/model_ex-006_acc-0.092308.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 2.5434 - acc: 0.2024 - val_loss: 4.1066 - val_acc: 0.0923\n",
      "Epoch 7/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.4828 - acc: 0.2337Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.1600 - acc: 0.1308\n",
      "Epoch 00007: saving model to /home/team2/fishgo/training/models/model_ex-007_acc-0.130769.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 2.4839 - acc: 0.2334 - val_loss: 3.1600 - val_acc: 0.1308\n",
      "Epoch 8/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.4572 - acc: 0.2488Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.6941 - acc: 0.1231\n",
      "Epoch 00008: saving model to /home/team2/fishgo/training/models/model_ex-008_acc-0.123077.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 2.4544 - acc: 0.2484 - val_loss: 3.6941 - val_acc: 0.1231\n",
      "Epoch 9/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.4626 - acc: 0.2564Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.1915 - acc: 0.1923\n",
      "Epoch 00009: saving model to /home/team2/fishgo/training/models/model_ex-009_acc-0.192308.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 2.4629 - acc: 0.2558 - val_loss: 3.1915 - val_acc: 0.1923\n",
      "Epoch 10/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.3498 - acc: 0.2752Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.9609 - acc: 0.2154\n",
      "Epoch 00010: saving model to /home/team2/fishgo/training/models/model_ex-010_acc-0.215385.h5\n",
      "108/108 [==============================] - 80s 739ms/step - loss: 2.3461 - acc: 0.2754 - val_loss: 2.9609 - val_acc: 0.2154\n",
      "Epoch 11/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.3772 - acc: 0.2620Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 6.2130 - acc: 0.0885\n",
      "Epoch 00011: saving model to /home/team2/fishgo/training/models/model_ex-011_acc-0.088462.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 2.3764 - acc: 0.2605 - val_loss: 6.2130 - val_acc: 0.0885\n",
      "Epoch 12/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.3362 - acc: 0.2762Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.9198 - acc: 0.1885\n",
      "Epoch 00012: saving model to /home/team2/fishgo/training/models/model_ex-012_acc-0.188462.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 2.3382 - acc: 0.2745 - val_loss: 2.9198 - val_acc: 0.1885\n",
      "Epoch 13/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.2902 - acc: 0.2879Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.0786 - acc: 0.1192\n",
      "Epoch 00013: saving model to /home/team2/fishgo/training/models/model_ex-013_acc-0.119231.h5\n",
      "108/108 [==============================] - 80s 742ms/step - loss: 2.2865 - acc: 0.2889 - val_loss: 4.0786 - val_acc: 0.1192\n",
      "Epoch 14/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.1682 - acc: 0.3251Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.8514 - acc: 0.2692\n",
      "Epoch 00014: saving model to /home/team2/fishgo/training/models/model_ex-014_acc-0.269231.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 2.1682 - acc: 0.3249 - val_loss: 2.8514 - val_acc: 0.2692\n",
      "Epoch 15/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.1969 - acc: 0.3205Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.7237 - acc: 0.2231\n",
      "Epoch 00015: saving model to /home/team2/fishgo/training/models/model_ex-015_acc-0.223077.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 2.1931 - acc: 0.3221 - val_loss: 2.7237 - val_acc: 0.2231\n",
      "Epoch 16/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.1730 - acc: 0.3223Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.6814 - acc: 0.2423\n",
      "Epoch 00016: saving model to /home/team2/fishgo/training/models/model_ex-016_acc-0.242308.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 2.1715 - acc: 0.3221 - val_loss: 2.6814 - val_acc: 0.2423\n",
      "Epoch 17/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.0220 - acc: 0.3794Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.4856 - acc: 0.1731\n",
      "Epoch 00017: saving model to /home/team2/fishgo/training/models/model_ex-017_acc-0.173077.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 2.0302 - acc: 0.3769 - val_loss: 3.4856 - val_acc: 0.1731\n",
      "Epoch 18/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 2.1171 - acc: 0.3375Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 6.3910 - acc: 0.1269\n",
      "Epoch 00018: saving model to /home/team2/fishgo/training/models/model_ex-018_acc-0.126923.h5\n",
      "108/108 [==============================] - 79s 732ms/step - loss: 2.1150 - acc: 0.3371 - val_loss: 6.3910 - val_acc: 0.1269\n",
      "Epoch 19/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.9762 - acc: 0.3804Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.3164 - acc: 0.1577\n",
      "Epoch 00019: saving model to /home/team2/fishgo/training/models/model_ex-019_acc-0.157692.h5\n",
      "108/108 [==============================] - 80s 742ms/step - loss: 1.9778 - acc: 0.3806 - val_loss: 3.3164 - val_acc: 0.1577\n",
      "Epoch 20/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.9438 - acc: 0.3850Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.1255 - acc: 0.1731\n",
      "Epoch 00020: saving model to /home/team2/fishgo/training/models/model_ex-020_acc-0.173077.h5\n",
      "108/108 [==============================] - 79s 730ms/step - loss: 1.9437 - acc: 0.3861 - val_loss: 3.1255 - val_acc: 0.1731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.8992 - acc: 0.4072Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.7581 - acc: 0.1577\n",
      "Epoch 00021: saving model to /home/team2/fishgo/training/models/model_ex-021_acc-0.157692.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 1.9023 - acc: 0.4052 - val_loss: 4.7581 - val_acc: 0.1577\n",
      "Epoch 22/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.8239 - acc: 0.4215Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.7722 - acc: 0.2769\n",
      "Epoch 00022: saving model to /home/team2/fishgo/training/models/model_ex-022_acc-0.276923.h5\n",
      "108/108 [==============================] - 80s 743ms/step - loss: 1.8207 - acc: 0.4213 - val_loss: 2.7722 - val_acc: 0.2769\n",
      "Epoch 23/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.8862 - acc: 0.4173Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 16s - loss: 3.7826 - acc: 0.2115\n",
      "Epoch 00023: saving model to /home/team2/fishgo/training/models/model_ex-023_acc-0.211538.h5\n",
      "108/108 [==============================] - 91s 839ms/step - loss: 1.8900 - acc: 0.4162 - val_loss: 3.7826 - val_acc: 0.2115\n",
      "Epoch 24/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7890 - acc: 0.4206Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 11s - loss: 3.4504 - acc: 0.1769\n",
      "Epoch 00024: saving model to /home/team2/fishgo/training/models/model_ex-024_acc-0.176923.h5\n",
      "108/108 [==============================] - 93s 860ms/step - loss: 1.7980 - acc: 0.4194 - val_loss: 3.4504 - val_acc: 0.1769\n",
      "Epoch 25/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7599 - acc: 0.4468Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.6452 - acc: 0.1615\n",
      "Epoch 00025: saving model to /home/team2/fishgo/training/models/model_ex-025_acc-0.161538.h5\n",
      "108/108 [==============================] - 97s 895ms/step - loss: 1.7620 - acc: 0.4473 - val_loss: 4.6452 - val_acc: 0.1615\n",
      "Epoch 26/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.6825 - acc: 0.4430Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 15s - loss: 3.1900 - acc: 0.2077\n",
      "Epoch 00026: saving model to /home/team2/fishgo/training/models/model_ex-026_acc-0.207692.h5\n",
      "108/108 [==============================] - 97s 903ms/step - loss: 1.6839 - acc: 0.4435 - val_loss: 3.1900 - val_acc: 0.2077\n",
      "Epoch 27/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.8187 - acc: 0.4449Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 15s - loss: 4.6616 - acc: 0.1385\n",
      "Epoch 00027: saving model to /home/team2/fishgo/training/models/model_ex-027_acc-0.138462.h5\n",
      "108/108 [==============================] - 98s 908ms/step - loss: 1.8154 - acc: 0.4454 - val_loss: 4.6616 - val_acc: 0.1385\n",
      "Epoch 28/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7437 - acc: 0.4477Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 15s - loss: 3.0471 - acc: 0.2500\n",
      "Epoch 00028: saving model to /home/team2/fishgo/training/models/model_ex-028_acc-0.250000.h5\n",
      "108/108 [==============================] - 106s 980ms/step - loss: 1.7412 - acc: 0.4491 - val_loss: 3.0471 - val_acc: 0.2500\n",
      "Epoch 29/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7661 - acc: 0.4373Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 15s - loss: 2.3850 - acc: 0.2923\n",
      "Epoch 00029: saving model to /home/team2/fishgo/training/models/model_ex-029_acc-0.292308.h5\n",
      "108/108 [==============================] - 100s 927ms/step - loss: 1.7618 - acc: 0.4379 - val_loss: 2.3850 - val_acc: 0.2923\n",
      "Epoch 30/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.6220 - acc: 0.4656Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 16s - loss: 2.8330 - acc: 0.2462\n",
      "Epoch 00030: saving model to /home/team2/fishgo/training/models/model_ex-030_acc-0.246154.h5\n",
      "108/108 [==============================] - 105s 975ms/step - loss: 1.6259 - acc: 0.4631 - val_loss: 2.8330 - val_acc: 0.2462\n",
      "Epoch 31/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.6038 - acc: 0.4910Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.8437 - acc: 0.2962\n",
      "Epoch 00031: saving model to /home/team2/fishgo/training/models/model_ex-031_acc-0.296154.h5\n",
      "108/108 [==============================] - 105s 970ms/step - loss: 1.6053 - acc: 0.4911 - val_loss: 2.8437 - val_acc: 0.2962\n",
      "Epoch 32/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.5700 - acc: 0.4863Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5714 - acc: 0.3385\n",
      "Epoch 00032: saving model to /home/team2/fishgo/training/models/model_ex-032_acc-0.338462.h5\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 1.5760 - acc: 0.4855 - val_loss: 2.5714 - val_acc: 0.3385\n",
      "Epoch 33/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.4460 - acc: 0.5364Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 7.8266 - acc: 0.1577\n",
      "Epoch 00033: saving model to /home/team2/fishgo/training/models/model_ex-033_acc-0.157692.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 1.4470 - acc: 0.5352 - val_loss: 7.8266 - val_acc: 0.1577\n",
      "Epoch 34/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.8509 - acc: 0.4249Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.5747 - acc: 0.2192\n",
      "Epoch 00034: saving model to /home/team2/fishgo/training/models/model_ex-034_acc-0.219231.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 1.8450 - acc: 0.4275 - val_loss: 4.5747 - val_acc: 0.2192\n",
      "Epoch 35/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.7368 - acc: 0.4515Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.7756 - acc: 0.2769\n",
      "Epoch 00035: saving model to /home/team2/fishgo/training/models/model_ex-035_acc-0.276923.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 1.7337 - acc: 0.4538 - val_loss: 3.7756 - val_acc: 0.2769\n",
      "Epoch 36/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.4157 - acc: 0.5439Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.0813 - acc: 0.2385\n",
      "Epoch 00036: saving model to /home/team2/fishgo/training/models/model_ex-036_acc-0.238462.h5\n",
      "108/108 [==============================] - 80s 742ms/step - loss: 1.4183 - acc: 0.5444 - val_loss: 4.0813 - val_acc: 0.2385\n",
      "Epoch 37/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.4800 - acc: 0.5485Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.8117 - acc: 0.3154\n",
      "Epoch 00037: saving model to /home/team2/fishgo/training/models/model_ex-037_acc-0.315385.h5\n",
      "108/108 [==============================] - 79s 733ms/step - loss: 1.4782 - acc: 0.5480 - val_loss: 3.8117 - val_acc: 0.3154\n",
      "Epoch 38/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.3896 - acc: 0.5523Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.9188 - acc: 0.2923\n",
      "Epoch 00038: saving model to /home/team2/fishgo/training/models/model_ex-038_acc-0.292308.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 1.3827 - acc: 0.5556 - val_loss: 2.9188 - val_acc: 0.2923\n",
      "Epoch 39/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.3623 - acc: 0.5316Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.1457 - acc: 0.2692\n",
      "Epoch 00039: saving model to /home/team2/fishgo/training/models/model_ex-039_acc-0.269231.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 1.3607 - acc: 0.5303 - val_loss: 4.1457 - val_acc: 0.2692\n",
      "Epoch 40/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.2298 - acc: 0.5910Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.1181 - acc: 0.2846\n",
      "Epoch 00040: saving model to /home/team2/fishgo/training/models/model_ex-040_acc-0.284615.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 1.2289 - acc: 0.5901 - val_loss: 3.1181 - val_acc: 0.2846\n",
      "Epoch 41/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.3503 - acc: 0.5646Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.9124 - acc: 0.3500\n",
      "Epoch 00041: saving model to /home/team2/fishgo/training/models/model_ex-041_acc-0.350000.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 1.3509 - acc: 0.5650 - val_loss: 2.9124 - val_acc: 0.3500\n",
      "Epoch 42/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.2124 - acc: 0.5928Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.7947 - acc: 0.3038\n",
      "Epoch 00042: saving model to /home/team2/fishgo/training/models/model_ex-042_acc-0.303846.h5\n",
      "108/108 [==============================] - 80s 742ms/step - loss: 1.2091 - acc: 0.5938 - val_loss: 2.7947 - val_acc: 0.3038\n",
      "Epoch 43/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.1477 - acc: 0.6336Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.2191 - acc: 0.2846\n",
      "Epoch 00043: saving model to /home/team2/fishgo/training/models/model_ex-043_acc-0.284615.h5\n",
      "108/108 [==============================] - 81s 745ms/step - loss: 1.1493 - acc: 0.6324 - val_loss: 3.2191 - val_acc: 0.2846\n",
      "Epoch 44/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.1508 - acc: 0.6362Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 7.3382 - acc: 0.2308\n",
      "Epoch 00044: saving model to /home/team2/fishgo/training/models/model_ex-044_acc-0.230769.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 1.1459 - acc: 0.6377 - val_loss: 7.3382 - val_acc: 0.2308\n",
      "Epoch 45/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.1401 - acc: 0.6287Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.7266 - acc: 0.3692\n",
      "Epoch 00045: saving model to /home/team2/fishgo/training/models/model_ex-045_acc-0.369231.h5\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 1.1413 - acc: 0.6284 - val_loss: 2.7266 - val_acc: 0.3692\n",
      "Epoch 46/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.0892 - acc: 0.6597Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4772 - acc: 0.3769\n",
      "Epoch 00046: saving model to /home/team2/fishgo/training/models/model_ex-046_acc-0.376923.h5\n",
      "108/108 [==============================] - 79s 732ms/step - loss: 1.0834 - acc: 0.6620 - val_loss: 2.4772 - val_acc: 0.3769\n",
      "Epoch 47/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.0642 - acc: 0.6467Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.0319 - acc: 0.4654\n",
      "Epoch 00047: saving model to /home/team2/fishgo/training/models/model_ex-047_acc-0.465385.h5\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 1.0694 - acc: 0.6454 - val_loss: 2.0319 - val_acc: 0.4654\n",
      "Epoch 48/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.0070 - acc: 0.6730Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.3329 - acc: 0.2538\n",
      "Epoch 00048: saving model to /home/team2/fishgo/training/models/model_ex-048_acc-0.253846.h5\n",
      "108/108 [==============================] - 79s 732ms/step - loss: 1.0136 - acc: 0.6714 - val_loss: 4.3329 - val_acc: 0.2538\n",
      "Epoch 49/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 1.0089 - acc: 0.6616Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.2292 - acc: 0.3808\n",
      "Epoch 00049: saving model to /home/team2/fishgo/training/models/model_ex-049_acc-0.380769.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 1.0138 - acc: 0.6611 - val_loss: 3.2292 - val_acc: 0.3808\n",
      "Epoch 50/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.8716 - acc: 0.7144Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.0538 - acc: 0.3308\n",
      "Epoch 00050: saving model to /home/team2/fishgo/training/models/model_ex-050_acc-0.330769.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.8732 - acc: 0.7134 - val_loss: 3.0538 - val_acc: 0.3308\n",
      "Epoch 51/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.9047 - acc: 0.6880Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2327 - acc: 0.4385\n",
      "Epoch 00051: saving model to /home/team2/fishgo/training/models/model_ex-051_acc-0.438462.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.9047 - acc: 0.6881 - val_loss: 2.2327 - val_acc: 0.4385\n",
      "Epoch 52/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.9041 - acc: 0.6907Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.5504 - acc: 0.3115\n",
      "Epoch 00052: saving model to /home/team2/fishgo/training/models/model_ex-052_acc-0.311538.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.9037 - acc: 0.6889 - val_loss: 3.5504 - val_acc: 0.3115\n",
      "Epoch 53/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.8376 - acc: 0.7163Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2251 - acc: 0.4385\n",
      "Epoch 00053: saving model to /home/team2/fishgo/training/models/model_ex-053_acc-0.438462.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.8388 - acc: 0.7143 - val_loss: 2.2251 - val_acc: 0.4385\n",
      "Epoch 54/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.9736 - acc: 0.6873Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.2458 - acc: 0.3615\n",
      "Epoch 00054: saving model to /home/team2/fishgo/training/models/model_ex-054_acc-0.361538.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.9766 - acc: 0.6864 - val_loss: 3.2458 - val_acc: 0.3615\n",
      "Epoch 55/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.8901 - acc: 0.7003Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 6.2065 - acc: 0.2462\n",
      "Epoch 00055: saving model to /home/team2/fishgo/training/models/model_ex-055_acc-0.246154.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.8899 - acc: 0.7003 - val_loss: 6.2065 - val_acc: 0.2462\n",
      "Epoch 56/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.7613 - acc: 0.7514Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.7595 - acc: 0.3846\n",
      "Epoch 00056: saving model to /home/team2/fishgo/training/models/model_ex-056_acc-0.384615.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.7614 - acc: 0.7509 - val_loss: 2.7595 - val_acc: 0.3846\n",
      "Epoch 57/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6675 - acc: 0.7908Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.5827 - acc: 0.3577\n",
      "Epoch 00057: saving model to /home/team2/fishgo/training/models/model_ex-057_acc-0.357692.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.6632 - acc: 0.7927 - val_loss: 3.5827 - val_acc: 0.3577\n",
      "Epoch 58/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.7970 - acc: 0.7568Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5467 - acc: 0.4038\n",
      "Epoch 00058: saving model to /home/team2/fishgo/training/models/model_ex-058_acc-0.403846.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.7937 - acc: 0.7582 - val_loss: 2.5467 - val_acc: 0.4038\n",
      "Epoch 59/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.7343 - acc: 0.7538Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3135 - acc: 0.4231\n",
      "Epoch 00059: saving model to /home/team2/fishgo/training/models/model_ex-059_acc-0.423077.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.7347 - acc: 0.7542 - val_loss: 2.3135 - val_acc: 0.4231\n",
      "Epoch 60/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6285 - acc: 0.7981Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.8173 - acc: 0.4269\n",
      "Epoch 00060: saving model to /home/team2/fishgo/training/models/model_ex-060_acc-0.426923.h5\n",
      "108/108 [==============================] - 80s 742ms/step - loss: 0.6244 - acc: 0.8000 - val_loss: 2.8173 - val_acc: 0.4269\n",
      "Epoch 61/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6569 - acc: 0.7672Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3291 - acc: 0.4538\n",
      "Epoch 00061: saving model to /home/team2/fishgo/training/models/model_ex-061_acc-0.453846.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 80s 737ms/step - loss: 0.6544 - acc: 0.7684 - val_loss: 2.3291 - val_acc: 0.4538\n",
      "Epoch 62/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6583 - acc: 0.7719Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3567 - acc: 0.4577\n",
      "Epoch 00062: saving model to /home/team2/fishgo/training/models/model_ex-062_acc-0.457692.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.6564 - acc: 0.7731 - val_loss: 2.3567 - val_acc: 0.4577\n",
      "Epoch 63/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.7733 - acc: 0.7614Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.2341 - acc: 0.3692\n",
      "Epoch 00063: saving model to /home/team2/fishgo/training/models/model_ex-063_acc-0.369231.h5\n",
      "108/108 [==============================] - 79s 730ms/step - loss: 0.7764 - acc: 0.7580 - val_loss: 3.2341 - val_acc: 0.3692\n",
      "Epoch 64/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.5374 - acc: 0.8224Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.9930 - acc: 0.4154\n",
      "Epoch 00064: saving model to /home/team2/fishgo/training/models/model_ex-064_acc-0.415385.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.5358 - acc: 0.8231 - val_loss: 2.9930 - val_acc: 0.4154\n",
      "Epoch 65/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6749 - acc: 0.7945Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2962 - acc: 0.4577\n",
      "Epoch 00065: saving model to /home/team2/fishgo/training/models/model_ex-065_acc-0.457692.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.6732 - acc: 0.7946 - val_loss: 2.2962 - val_acc: 0.4577\n",
      "Epoch 66/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.7956Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.0631 - acc: 0.3962\n",
      "Epoch 00066: saving model to /home/team2/fishgo/training/models/model_ex-066_acc-0.396154.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.6267 - acc: 0.7976 - val_loss: 3.0631 - val_acc: 0.3962\n",
      "Epoch 67/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.5948 - acc: 0.8000Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2797 - acc: 0.4654\n",
      "Epoch 00067: saving model to /home/team2/fishgo/training/models/model_ex-067_acc-0.465385.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.5949 - acc: 0.7991 - val_loss: 2.2797 - val_acc: 0.4654\n",
      "Epoch 68/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.5511 - acc: 0.8146Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 8.3681 - acc: 0.3000\n",
      "Epoch 00068: saving model to /home/team2/fishgo/training/models/model_ex-068_acc-0.300000.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.5499 - acc: 0.8145 - val_loss: 8.3681 - val_acc: 0.3000\n",
      "Epoch 69/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.5725 - acc: 0.8153Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.9948 - acc: 0.3615\n",
      "Epoch 00069: saving model to /home/team2/fishgo/training/models/model_ex-069_acc-0.361538.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.5691 - acc: 0.8161 - val_loss: 2.9948 - val_acc: 0.3615\n",
      "Epoch 70/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.5667 - acc: 0.8209Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 4.2478 - acc: 0.3038\n",
      "Epoch 00070: saving model to /home/team2/fishgo/training/models/model_ex-070_acc-0.303846.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.5626 - acc: 0.8226 - val_loss: 4.2478 - val_acc: 0.3038\n",
      "Epoch 71/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.4315 - acc: 0.8586Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3684 - acc: 0.5154\n",
      "Epoch 00071: saving model to /home/team2/fishgo/training/models/model_ex-071_acc-0.515385.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.4289 - acc: 0.8590 - val_loss: 2.3684 - val_acc: 0.5154\n",
      "Epoch 72/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.4975 - acc: 0.8439Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.9989 - acc: 0.5000\n",
      "Epoch 00072: saving model to /home/team2/fishgo/training/models/model_ex-072_acc-0.500000.h5\n",
      "108/108 [==============================] - 80s 743ms/step - loss: 0.4970 - acc: 0.8444 - val_loss: 2.9989 - val_acc: 0.5000\n",
      "Epoch 73/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.4745 - acc: 0.8460Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.6297 - acc: 0.4231\n",
      "Epoch 00073: saving model to /home/team2/fishgo/training/models/model_ex-073_acc-0.423077.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.4706 - acc: 0.8475 - val_loss: 2.6297 - val_acc: 0.4231\n",
      "Epoch 74/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.3719 - acc: 0.8626Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 3.0573 - acc: 0.4038\n",
      "Epoch 00074: saving model to /home/team2/fishgo/training/models/model_ex-074_acc-0.403846.h5\n",
      "108/108 [==============================] - 80s 742ms/step - loss: 0.3733 - acc: 0.8620 - val_loss: 3.0573 - val_acc: 0.4038\n",
      "Epoch 75/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8451Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.6478 - acc: 0.4462\n",
      "Epoch 00075: saving model to /home/team2/fishgo/training/models/model_ex-075_acc-0.446154.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.4576 - acc: 0.8456 - val_loss: 2.6478 - val_acc: 0.4462\n",
      "Epoch 76/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.3688 - acc: 0.8813Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3508 - acc: 0.4808\n",
      "Epoch 00076: saving model to /home/team2/fishgo/training/models/model_ex-076_acc-0.480769.h5\n",
      "108/108 [==============================] - 80s 743ms/step - loss: 0.3690 - acc: 0.8815 - val_loss: 2.3508 - val_acc: 0.4808\n",
      "Epoch 77/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.3766 - acc: 0.8671Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5075 - acc: 0.5308\n",
      "Epoch 00077: saving model to /home/team2/fishgo/training/models/model_ex-077_acc-0.530769.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.3821 - acc: 0.8646 - val_loss: 2.5075 - val_acc: 0.5308\n",
      "Epoch 78/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.3682 - acc: 0.8709Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2345 - acc: 0.5038\n",
      "Epoch 00078: saving model to /home/team2/fishgo/training/models/model_ex-078_acc-0.503846.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.3677 - acc: 0.8702 - val_loss: 2.2345 - val_acc: 0.5038\n",
      "Epoch 79/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.4193 - acc: 0.8586Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.8278 - acc: 0.4731\n",
      "Epoch 00079: saving model to /home/team2/fishgo/training/models/model_ex-079_acc-0.473077.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.4195 - acc: 0.8590 - val_loss: 2.8278 - val_acc: 0.4731\n",
      "Epoch 80/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.3555 - acc: 0.8641Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.6494 - acc: 0.4885\n",
      "Epoch 00080: saving model to /home/team2/fishgo/training/models/model_ex-080_acc-0.488462.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.3526 - acc: 0.8653 - val_loss: 2.6494 - val_acc: 0.4885\n",
      "Epoch 81/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.3305 - acc: 0.8822Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5164 - acc: 0.5269\n",
      "Epoch 00081: saving model to /home/team2/fishgo/training/models/model_ex-081_acc-0.526923.h5\n",
      "108/108 [==============================] - 81s 746ms/step - loss: 0.3334 - acc: 0.8824 - val_loss: 2.5164 - val_acc: 0.5269\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/108 [============================>.] - ETA: 0s - loss: 0.2496 - acc: 0.9246Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.0574 - acc: 0.5615\n",
      "Epoch 00082: saving model to /home/team2/fishgo/training/models/model_ex-082_acc-0.561538.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.2472 - acc: 0.9253 - val_loss: 2.0574 - val_acc: 0.5615\n",
      "Epoch 83/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9487Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.0640 - acc: 0.5538\n",
      "Epoch 00083: saving model to /home/team2/fishgo/training/models/model_ex-083_acc-0.553846.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.1823 - acc: 0.9482 - val_loss: 2.0640 - val_acc: 0.5538\n",
      "Epoch 84/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9570Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 1.9966 - acc: 0.5692\n",
      "Epoch 00084: saving model to /home/team2/fishgo/training/models/model_ex-084_acc-0.569231.h5\n",
      "108/108 [==============================] - 81s 747ms/step - loss: 0.1417 - acc: 0.9565 - val_loss: 1.9966 - val_acc: 0.5692\n",
      "Epoch 85/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9670Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.0135 - acc: 0.5846\n",
      "Epoch 00085: saving model to /home/team2/fishgo/training/models/model_ex-085_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 739ms/step - loss: 0.1205 - acc: 0.9664 - val_loss: 2.0135 - val_acc: 0.5846\n",
      "Epoch 86/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9642Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.0887 - acc: 0.5846\n",
      "Epoch 00086: saving model to /home/team2/fishgo/training/models/model_ex-086_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 0.1350 - acc: 0.9645 - val_loss: 2.0887 - val_acc: 0.5846\n",
      "Epoch 87/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9743Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.1132 - acc: 0.5692\n",
      "Epoch 00087: saving model to /home/team2/fishgo/training/models/model_ex-087_acc-0.569231.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.1219 - acc: 0.9746 - val_loss: 2.1132 - val_acc: 0.5692\n",
      "Epoch 88/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9673Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.1155 - acc: 0.5769\n",
      "Epoch 00088: saving model to /home/team2/fishgo/training/models/model_ex-088_acc-0.576923.h5\n",
      "108/108 [==============================] - 80s 744ms/step - loss: 0.1012 - acc: 0.9676 - val_loss: 2.1155 - val_acc: 0.5769\n",
      "Epoch 89/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9708Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.1069 - acc: 0.5808\n",
      "Epoch 00089: saving model to /home/team2/fishgo/training/models/model_ex-089_acc-0.580769.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.1387 - acc: 0.9711 - val_loss: 2.1069 - val_acc: 0.5808\n",
      "Epoch 90/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9614Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2019 - acc: 0.5769\n",
      "Epoch 00090: saving model to /home/team2/fishgo/training/models/model_ex-090_acc-0.576923.h5\n",
      "108/108 [==============================] - 80s 739ms/step - loss: 0.1177 - acc: 0.9617 - val_loss: 2.2019 - val_acc: 0.5769\n",
      "Epoch 91/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9642Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.1259 - acc: 0.5923\n",
      "Epoch 00091: saving model to /home/team2/fishgo/training/models/model_ex-091_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.1118 - acc: 0.9645 - val_loss: 2.1259 - val_acc: 0.5923\n",
      "Epoch 92/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9755Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2044 - acc: 0.5846\n",
      "Epoch 00092: saving model to /home/team2/fishgo/training/models/model_ex-092_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0973 - acc: 0.9757 - val_loss: 2.2044 - val_acc: 0.5846\n",
      "Epoch 93/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9623Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2064 - acc: 0.5885\n",
      "Epoch 00093: saving model to /home/team2/fishgo/training/models/model_ex-093_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.1176 - acc: 0.9627 - val_loss: 2.2064 - val_acc: 0.5885\n",
      "Epoch 94/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9708Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.1987 - acc: 0.5808\n",
      "Epoch 00094: saving model to /home/team2/fishgo/training/models/model_ex-094_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.1039 - acc: 0.9711 - val_loss: 2.1987 - val_acc: 0.5808\n",
      "Epoch 95/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9793Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2538 - acc: 0.5769\n",
      "Epoch 00095: saving model to /home/team2/fishgo/training/models/model_ex-095_acc-0.576923.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0900 - acc: 0.9785 - val_loss: 2.2538 - val_acc: 0.5769\n",
      "Epoch 96/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9689Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3242 - acc: 0.5346\n",
      "Epoch 00096: saving model to /home/team2/fishgo/training/models/model_ex-096_acc-0.534615.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0960 - acc: 0.9692 - val_loss: 2.3242 - val_acc: 0.5346\n",
      "Epoch 97/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9689Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2179 - acc: 0.5923\n",
      "Epoch 00097: saving model to /home/team2/fishgo/training/models/model_ex-097_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.1040 - acc: 0.9692 - val_loss: 2.2179 - val_acc: 0.5923\n",
      "Epoch 98/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9753Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3991 - acc: 0.5808\n",
      "Epoch 00098: saving model to /home/team2/fishgo/training/models/model_ex-098_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.1014 - acc: 0.9755 - val_loss: 2.3991 - val_acc: 0.5808\n",
      "Epoch 99/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9738Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3184 - acc: 0.5962\n",
      "Epoch 00099: saving model to /home/team2/fishgo/training/models/model_ex-099_acc-0.596154.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.0856 - acc: 0.9741 - val_loss: 2.3184 - val_acc: 0.5962\n",
      "Epoch 100/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9755Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4180 - acc: 0.5846\n",
      "Epoch 00100: saving model to /home/team2/fishgo/training/models/model_ex-100_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.1262 - acc: 0.9757 - val_loss: 2.4180 - val_acc: 0.5846\n",
      "Epoch 101/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9774Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4889 - acc: 0.5538\n",
      "Epoch 00101: saving model to /home/team2/fishgo/training/models/model_ex-101_acc-0.553846.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.1130 - acc: 0.9757 - val_loss: 2.4889 - val_acc: 0.5538\n",
      "Epoch 102/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9774Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3413 - acc: 0.5846\n",
      "Epoch 00102: saving model to /home/team2/fishgo/training/models/model_ex-102_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0916 - acc: 0.9776 - val_loss: 2.3413 - val_acc: 0.5846\n",
      "Epoch 103/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9708Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3519 - acc: 0.5654\n",
      "Epoch 00103: saving model to /home/team2/fishgo/training/models/model_ex-103_acc-0.565385.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0938 - acc: 0.9711 - val_loss: 2.3519 - val_acc: 0.5654\n",
      "Epoch 104/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9802Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2639 - acc: 0.5846\n",
      "Epoch 00104: saving model to /home/team2/fishgo/training/models/model_ex-104_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0766 - acc: 0.9804 - val_loss: 2.2639 - val_acc: 0.5846\n",
      "Epoch 105/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9727Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3548 - acc: 0.5500\n",
      "Epoch 00105: saving model to /home/team2/fishgo/training/models/model_ex-105_acc-0.550000.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0981 - acc: 0.9729 - val_loss: 2.3548 - val_acc: 0.5500\n",
      "Epoch 106/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9821Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2934 - acc: 0.5615\n",
      "Epoch 00106: saving model to /home/team2/fishgo/training/models/model_ex-106_acc-0.561538.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0949 - acc: 0.9823 - val_loss: 2.2934 - val_acc: 0.5615\n",
      "Epoch 107/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9764Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.2772 - acc: 0.5846\n",
      "Epoch 00107: saving model to /home/team2/fishgo/training/models/model_ex-107_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 739ms/step - loss: 0.0806 - acc: 0.9767 - val_loss: 2.2772 - val_acc: 0.5846\n",
      "Epoch 108/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9811Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3018 - acc: 0.5885\n",
      "Epoch 00108: saving model to /home/team2/fishgo/training/models/model_ex-108_acc-0.588462.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.0871 - acc: 0.9813 - val_loss: 2.3018 - val_acc: 0.5885\n",
      "Epoch 109/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9764Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3187 - acc: 0.5885\n",
      "Epoch 00109: saving model to /home/team2/fishgo/training/models/model_ex-109_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0950 - acc: 0.9757 - val_loss: 2.3187 - val_acc: 0.5885\n",
      "Epoch 110/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9736Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4353 - acc: 0.5462\n",
      "Epoch 00110: saving model to /home/team2/fishgo/training/models/model_ex-110_acc-0.546154.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0838 - acc: 0.9739 - val_loss: 2.4353 - val_acc: 0.5462\n",
      "Epoch 111/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9764Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3782 - acc: 0.5885\n",
      "Epoch 00111: saving model to /home/team2/fishgo/training/models/model_ex-111_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0703 - acc: 0.9767 - val_loss: 2.3782 - val_acc: 0.5885\n",
      "Epoch 112/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9736Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4826 - acc: 0.5731\n",
      "Epoch 00112: saving model to /home/team2/fishgo/training/models/model_ex-112_acc-0.573077.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.0895 - acc: 0.9739 - val_loss: 2.4826 - val_acc: 0.5731\n",
      "Epoch 113/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9821Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5147 - acc: 0.5654\n",
      "Epoch 00113: saving model to /home/team2/fishgo/training/models/model_ex-113_acc-0.565385.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0827 - acc: 0.9823 - val_loss: 2.5147 - val_acc: 0.5654\n",
      "Epoch 114/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9774Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4537 - acc: 0.5538\n",
      "Epoch 00114: saving model to /home/team2/fishgo/training/models/model_ex-114_acc-0.553846.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0796 - acc: 0.9776 - val_loss: 2.4537 - val_acc: 0.5538\n",
      "Epoch 115/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9755Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4185 - acc: 0.5577\n",
      "Epoch 00115: saving model to /home/team2/fishgo/training/models/model_ex-115_acc-0.557692.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0755 - acc: 0.9757 - val_loss: 2.4185 - val_acc: 0.5577\n",
      "Epoch 116/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9868Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.3668 - acc: 0.5808\n",
      "Epoch 00116: saving model to /home/team2/fishgo/training/models/model_ex-116_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0658 - acc: 0.9869 - val_loss: 2.3668 - val_acc: 0.5808\n",
      "Epoch 117/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9727Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4619 - acc: 0.5615\n",
      "Epoch 00117: saving model to /home/team2/fishgo/training/models/model_ex-117_acc-0.561538.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0853 - acc: 0.9729 - val_loss: 2.4619 - val_acc: 0.5615\n",
      "Epoch 118/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9717Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5932 - acc: 0.5577\n",
      "Epoch 00118: saving model to /home/team2/fishgo/training/models/model_ex-118_acc-0.557692.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0833 - acc: 0.9720 - val_loss: 2.5932 - val_acc: 0.5577\n",
      "Epoch 119/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9811Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5295 - acc: 0.5731\n",
      "Epoch 00119: saving model to /home/team2/fishgo/training/models/model_ex-119_acc-0.573077.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0814 - acc: 0.9813 - val_loss: 2.5295 - val_acc: 0.5731\n",
      "Epoch 120/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9774Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4438 - acc: 0.5692\n",
      "Epoch 00120: saving model to /home/team2/fishgo/training/models/model_ex-120_acc-0.569231.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0834 - acc: 0.9776 - val_loss: 2.4438 - val_acc: 0.5692\n",
      "Epoch 121/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9689Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5146 - acc: 0.5692\n",
      "Epoch 00121: saving model to /home/team2/fishgo/training/models/model_ex-121_acc-0.569231.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0950 - acc: 0.9692 - val_loss: 2.5146 - val_acc: 0.5692\n",
      "Epoch 122/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9783Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4654 - acc: 0.5808\n",
      "Epoch 00122: saving model to /home/team2/fishgo/training/models/model_ex-122_acc-0.580769.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0912 - acc: 0.9785 - val_loss: 2.4654 - val_acc: 0.5808\n",
      "Epoch 123/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9802Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4519 - acc: 0.5731\n",
      "Epoch 00123: saving model to /home/team2/fishgo/training/models/model_ex-123_acc-0.573077.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0709 - acc: 0.9804 - val_loss: 2.4519 - val_acc: 0.5731\n",
      "Epoch 124/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9840Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4534 - acc: 0.5769\n",
      "Epoch 00124: saving model to /home/team2/fishgo/training/models/model_ex-124_acc-0.576923.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0621 - acc: 0.9841 - val_loss: 2.4534 - val_acc: 0.5769\n",
      "Epoch 125/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9840Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4236 - acc: 0.5808\n",
      "Epoch 00125: saving model to /home/team2/fishgo/training/models/model_ex-125_acc-0.580769.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0531 - acc: 0.9841 - val_loss: 2.4236 - val_acc: 0.5808\n",
      "Epoch 126/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9849Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4235 - acc: 0.5846\n",
      "Epoch 00126: saving model to /home/team2/fishgo/training/models/model_ex-126_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.0579 - acc: 0.9851 - val_loss: 2.4235 - val_acc: 0.5846\n",
      "Epoch 127/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9794Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4228 - acc: 0.5769\n",
      "Epoch 00127: saving model to /home/team2/fishgo/training/models/model_ex-127_acc-0.576923.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.0584 - acc: 0.9796 - val_loss: 2.4228 - val_acc: 0.5769\n",
      "Epoch 128/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9868Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4245 - acc: 0.5769\n",
      "Epoch 00128: saving model to /home/team2/fishgo/training/models/model_ex-128_acc-0.576923.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0518 - acc: 0.9869 - val_loss: 2.4245 - val_acc: 0.5769\n",
      "Epoch 129/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9838Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4325 - acc: 0.5769\n",
      "Epoch 00129: saving model to /home/team2/fishgo/training/models/model_ex-129_acc-0.576923.h5\n",
      "108/108 [==============================] - 79s 730ms/step - loss: 0.0522 - acc: 0.9840 - val_loss: 2.4325 - val_acc: 0.5769\n",
      "Epoch 130/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9821Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4205 - acc: 0.5846\n",
      "Epoch 00130: saving model to /home/team2/fishgo/training/models/model_ex-130_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0555 - acc: 0.9823 - val_loss: 2.4205 - val_acc: 0.5846\n",
      "Epoch 131/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9811Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4337 - acc: 0.5769\n",
      "Epoch 00131: saving model to /home/team2/fishgo/training/models/model_ex-131_acc-0.576923.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0629 - acc: 0.9813 - val_loss: 2.4337 - val_acc: 0.5769\n",
      "Epoch 132/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9813Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4082 - acc: 0.5923\n",
      "Epoch 00132: saving model to /home/team2/fishgo/training/models/model_ex-132_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 742ms/step - loss: 0.0565 - acc: 0.9815 - val_loss: 2.4082 - val_acc: 0.5923\n",
      "Epoch 133/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9859Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4448 - acc: 0.5808\n",
      "Epoch 00133: saving model to /home/team2/fishgo/training/models/model_ex-133_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0532 - acc: 0.9860 - val_loss: 2.4448 - val_acc: 0.5808\n",
      "Epoch 134/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9848Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4433 - acc: 0.5808\n",
      "Epoch 00134: saving model to /home/team2/fishgo/training/models/model_ex-134_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0738 - acc: 0.9849 - val_loss: 2.4433 - val_acc: 0.5808\n",
      "Epoch 135/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9860Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4412 - acc: 0.5808\n",
      "Epoch 00135: saving model to /home/team2/fishgo/training/models/model_ex-135_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0496 - acc: 0.9860 - val_loss: 2.4412 - val_acc: 0.5808\n",
      "Epoch 136/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9821Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4418 - acc: 0.5808\n",
      "Epoch 00136: saving model to /home/team2/fishgo/training/models/model_ex-136_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0669 - acc: 0.9823 - val_loss: 2.4418 - val_acc: 0.5808\n",
      "Epoch 137/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9802Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4471 - acc: 0.5769\n",
      "Epoch 00137: saving model to /home/team2/fishgo/training/models/model_ex-137_acc-0.576923.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0618 - acc: 0.9804 - val_loss: 2.4471 - val_acc: 0.5769\n",
      "Epoch 138/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9849Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4402 - acc: 0.5885\n",
      "Epoch 00138: saving model to /home/team2/fishgo/training/models/model_ex-138_acc-0.588462.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0475 - acc: 0.9851 - val_loss: 2.4402 - val_acc: 0.5885\n",
      "Epoch 139/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9850Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4554 - acc: 0.5923\n",
      "Epoch 00139: saving model to /home/team2/fishgo/training/models/model_ex-139_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.0521 - acc: 0.9852 - val_loss: 2.4554 - val_acc: 0.5923\n",
      "Epoch 140/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9755Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4457 - acc: 0.5885\n",
      "Epoch 00140: saving model to /home/team2/fishgo/training/models/model_ex-140_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0754 - acc: 0.9757 - val_loss: 2.4457 - val_acc: 0.5885\n",
      "Epoch 141/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9906Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4624 - acc: 0.5885\n",
      "Epoch 00141: saving model to /home/team2/fishgo/training/models/model_ex-141_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0639 - acc: 0.9907 - val_loss: 2.4624 - val_acc: 0.5885\n",
      "Epoch 142/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9915Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4340 - acc: 0.5885\n",
      "Epoch 00142: saving model to /home/team2/fishgo/training/models/model_ex-142_acc-0.588462.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0400 - acc: 0.9916 - val_loss: 2.4340 - val_acc: 0.5885\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/108 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9802Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4499 - acc: 0.5923\n",
      "Epoch 00143: saving model to /home/team2/fishgo/training/models/model_ex-143_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.0802 - acc: 0.9795 - val_loss: 2.4499 - val_acc: 0.5923\n",
      "Epoch 144/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9914Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4520 - acc: 0.5846\n",
      "Epoch 00144: saving model to /home/team2/fishgo/training/models/model_ex-144_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 729ms/step - loss: 0.0445 - acc: 0.9915 - val_loss: 2.4520 - val_acc: 0.5846\n",
      "Epoch 145/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9841Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4527 - acc: 0.5923\n",
      "Epoch 00145: saving model to /home/team2/fishgo/training/models/model_ex-145_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0486 - acc: 0.9841 - val_loss: 2.4527 - val_acc: 0.5923\n",
      "Epoch 146/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9859Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4822 - acc: 0.5923\n",
      "Epoch 00146: saving model to /home/team2/fishgo/training/models/model_ex-146_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0578 - acc: 0.9860 - val_loss: 2.4822 - val_acc: 0.5923\n",
      "Epoch 147/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9849Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4626 - acc: 0.5885\n",
      "Epoch 00147: saving model to /home/team2/fishgo/training/models/model_ex-147_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0716 - acc: 0.9851 - val_loss: 2.4626 - val_acc: 0.5885\n",
      "Epoch 148/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9869Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4624 - acc: 0.5846\n",
      "Epoch 00148: saving model to /home/team2/fishgo/training/models/model_ex-148_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.0444 - acc: 0.9861 - val_loss: 2.4624 - val_acc: 0.5846\n",
      "Epoch 149/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9867Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4658 - acc: 0.5923\n",
      "Epoch 00149: saving model to /home/team2/fishgo/training/models/model_ex-149_acc-0.592308.h5\n",
      "108/108 [==============================] - 79s 730ms/step - loss: 0.0624 - acc: 0.9868 - val_loss: 2.4658 - val_acc: 0.5923\n",
      "Epoch 150/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9802Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4423 - acc: 0.5962\n",
      "Epoch 00150: saving model to /home/team2/fishgo/training/models/model_ex-150_acc-0.596154.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0602 - acc: 0.9795 - val_loss: 2.4423 - val_acc: 0.5962\n",
      "Epoch 151/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9822Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4295 - acc: 0.5923\n",
      "Epoch 00151: saving model to /home/team2/fishgo/training/models/model_ex-151_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.0553 - acc: 0.9824 - val_loss: 2.4295 - val_acc: 0.5923\n",
      "Epoch 152/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9886Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4636 - acc: 0.5885\n",
      "Epoch 00152: saving model to /home/team2/fishgo/training/models/model_ex-152_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.1097 - acc: 0.9878 - val_loss: 2.4636 - val_acc: 0.5885\n",
      "Epoch 153/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9849Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4818 - acc: 0.5846\n",
      "Epoch 00153: saving model to /home/team2/fishgo/training/models/model_ex-153_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0669 - acc: 0.9851 - val_loss: 2.4818 - val_acc: 0.5846\n",
      "Epoch 154/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9802Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4611 - acc: 0.5846\n",
      "Epoch 00154: saving model to /home/team2/fishgo/training/models/model_ex-154_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0566 - acc: 0.9804 - val_loss: 2.4611 - val_acc: 0.5846\n",
      "Epoch 155/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9849Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4671 - acc: 0.5885\n",
      "Epoch 00155: saving model to /home/team2/fishgo/training/models/model_ex-155_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0535 - acc: 0.9851 - val_loss: 2.4671 - val_acc: 0.5885\n",
      "Epoch 156/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9877Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4683 - acc: 0.5846\n",
      "Epoch 00156: saving model to /home/team2/fishgo/training/models/model_ex-156_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0475 - acc: 0.9879 - val_loss: 2.4683 - val_acc: 0.5846\n",
      "Epoch 157/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9896Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4590 - acc: 0.5923\n",
      "Epoch 00157: saving model to /home/team2/fishgo/training/models/model_ex-157_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.0598 - acc: 0.9897 - val_loss: 2.4590 - val_acc: 0.5923\n",
      "Epoch 158/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9830Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4818 - acc: 0.5808\n",
      "Epoch 00158: saving model to /home/team2/fishgo/training/models/model_ex-158_acc-0.580769.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0691 - acc: 0.9832 - val_loss: 2.4818 - val_acc: 0.5808\n",
      "Epoch 159/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9804Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4751 - acc: 0.5846\n",
      "Epoch 00159: saving model to /home/team2/fishgo/training/models/model_ex-159_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 742ms/step - loss: 0.0583 - acc: 0.9806 - val_loss: 2.4751 - val_acc: 0.5846\n",
      "Epoch 160/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9906Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4908 - acc: 0.5885\n",
      "Epoch 00160: saving model to /home/team2/fishgo/training/models/model_ex-160_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.0609 - acc: 0.9896 - val_loss: 2.4908 - val_acc: 0.5885\n",
      "Epoch 161/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9888Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4928 - acc: 0.5885\n",
      "Epoch 00161: saving model to /home/team2/fishgo/training/models/model_ex-161_acc-0.588462.h5\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 0.0453 - acc: 0.9889 - val_loss: 2.4928 - val_acc: 0.5885\n",
      "Epoch 162/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9848Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4812 - acc: 0.5846\n",
      "Epoch 00162: saving model to /home/team2/fishgo/training/models/model_ex-162_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.0588 - acc: 0.9849 - val_loss: 2.4812 - val_acc: 0.5846\n",
      "Epoch 163/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9868Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4651 - acc: 0.5846\n",
      "Epoch 00163: saving model to /home/team2/fishgo/training/models/model_ex-163_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0509 - acc: 0.9869 - val_loss: 2.4651 - val_acc: 0.5846\n",
      "Epoch 164/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9811Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4770 - acc: 0.5846\n",
      "Epoch 00164: saving model to /home/team2/fishgo/training/models/model_ex-164_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0543 - acc: 0.9813 - val_loss: 2.4770 - val_acc: 0.5846\n",
      "Epoch 165/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9802Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5083 - acc: 0.5808\n",
      "Epoch 00165: saving model to /home/team2/fishgo/training/models/model_ex-165_acc-0.580769.h5\n",
      "108/108 [==============================] - 80s 743ms/step - loss: 0.0664 - acc: 0.9795 - val_loss: 2.5083 - val_acc: 0.5808\n",
      "Epoch 166/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9879Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 13s - loss: 2.4837 - acc: 0.5769\n",
      "Epoch 00166: saving model to /home/team2/fishgo/training/models/model_ex-166_acc-0.576923.h5\n",
      "108/108 [==============================] - 87s 806ms/step - loss: 0.0456 - acc: 0.9880 - val_loss: 2.4837 - val_acc: 0.5769\n",
      "Epoch 167/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9896Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4712 - acc: 0.5885\n",
      "Epoch 00167: saving model to /home/team2/fishgo/training/models/model_ex-167_acc-0.588462.h5\n",
      "108/108 [==============================] - 80s 739ms/step - loss: 0.0409 - acc: 0.9897 - val_loss: 2.4712 - val_acc: 0.5885\n",
      "Epoch 168/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9857Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4758 - acc: 0.5808\n",
      "Epoch 00168: saving model to /home/team2/fishgo/training/models/model_ex-168_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 732ms/step - loss: 0.0629 - acc: 0.9859 - val_loss: 2.4758 - val_acc: 0.5808\n",
      "Epoch 169/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9821Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4713 - acc: 0.6000\n",
      "Epoch 00169: saving model to /home/team2/fishgo/training/models/model_ex-169_acc-0.600000.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0656 - acc: 0.9823 - val_loss: 2.4713 - val_acc: 0.6000\n",
      "Epoch 170/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9849Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4623 - acc: 0.6038\n",
      "Epoch 00170: saving model to /home/team2/fishgo/training/models/model_ex-170_acc-0.603846.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0566 - acc: 0.9851 - val_loss: 2.4623 - val_acc: 0.6038\n",
      "Epoch 171/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9830Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4651 - acc: 0.5885\n",
      "Epoch 00171: saving model to /home/team2/fishgo/training/models/model_ex-171_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0738 - acc: 0.9832 - val_loss: 2.4651 - val_acc: 0.5885\n",
      "Epoch 172/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9840Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4852 - acc: 0.5808\n",
      "Epoch 00172: saving model to /home/team2/fishgo/training/models/model_ex-172_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0616 - acc: 0.9841 - val_loss: 2.4852 - val_acc: 0.5808\n",
      "Epoch 173/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9907Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4585 - acc: 0.5962\n",
      "Epoch 00173: saving model to /home/team2/fishgo/training/models/model_ex-173_acc-0.596154.h5\n",
      "108/108 [==============================] - 80s 741ms/step - loss: 0.0406 - acc: 0.9898 - val_loss: 2.4585 - val_acc: 0.5962\n",
      "Epoch 174/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9868Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4891 - acc: 0.5846\n",
      "Epoch 00174: saving model to /home/team2/fishgo/training/models/model_ex-174_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0559 - acc: 0.9869 - val_loss: 2.4891 - val_acc: 0.5846\n",
      "Epoch 175/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9849Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4887 - acc: 0.5885\n",
      "Epoch 00175: saving model to /home/team2/fishgo/training/models/model_ex-175_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0509 - acc: 0.9841 - val_loss: 2.4887 - val_acc: 0.5885\n",
      "Epoch 176/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9868Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4940 - acc: 0.5846\n",
      "Epoch 00176: saving model to /home/team2/fishgo/training/models/model_ex-176_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 733ms/step - loss: 0.0483 - acc: 0.9869 - val_loss: 2.4940 - val_acc: 0.5846\n",
      "Epoch 177/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9896Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4939 - acc: 0.5808\n",
      "Epoch 00177: saving model to /home/team2/fishgo/training/models/model_ex-177_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0499 - acc: 0.9897 - val_loss: 2.4939 - val_acc: 0.5808\n",
      "Epoch 178/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9914Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4994 - acc: 0.5846\n",
      "Epoch 00178: saving model to /home/team2/fishgo/training/models/model_ex-178_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 730ms/step - loss: 0.0465 - acc: 0.9915 - val_loss: 2.4994 - val_acc: 0.5846\n",
      "Epoch 179/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9840Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4930 - acc: 0.5885\n",
      "Epoch 00179: saving model to /home/team2/fishgo/training/models/model_ex-179_acc-0.588462.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0541 - acc: 0.9841 - val_loss: 2.4930 - val_acc: 0.5885\n",
      "Epoch 180/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9888Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4857 - acc: 0.5846\n",
      "Epoch 00180: saving model to /home/team2/fishgo/training/models/model_ex-180_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 739ms/step - loss: 0.0455 - acc: 0.9889 - val_loss: 2.4857 - val_acc: 0.5846\n",
      "Epoch 181/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9830Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4999 - acc: 0.5885\n",
      "Epoch 00181: saving model to /home/team2/fishgo/training/models/model_ex-181_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0559 - acc: 0.9823 - val_loss: 2.4999 - val_acc: 0.5885\n",
      "Epoch 182/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9896Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5010 - acc: 0.5846\n",
      "Epoch 00182: saving model to /home/team2/fishgo/training/models/model_ex-182_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0723 - acc: 0.9897 - val_loss: 2.5010 - val_acc: 0.5846\n",
      "Epoch 183/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9849Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4805 - acc: 0.5923\n",
      "Epoch 00183: saving model to /home/team2/fishgo/training/models/model_ex-183_acc-0.592308.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0566 - acc: 0.9851 - val_loss: 2.4805 - val_acc: 0.5923\n",
      "Epoch 184/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9793Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4832 - acc: 0.5846\n",
      "Epoch 00184: saving model to /home/team2/fishgo/training/models/model_ex-184_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0543 - acc: 0.9795 - val_loss: 2.4832 - val_acc: 0.5846\n",
      "Epoch 185/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9859Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4869 - acc: 0.5769\n",
      "Epoch 00185: saving model to /home/team2/fishgo/training/models/model_ex-185_acc-0.576923.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0563 - acc: 0.9851 - val_loss: 2.4869 - val_acc: 0.5769\n",
      "Epoch 186/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9896Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4873 - acc: 0.5846\n",
      "Epoch 00186: saving model to /home/team2/fishgo/training/models/model_ex-186_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0422 - acc: 0.9897 - val_loss: 2.4873 - val_acc: 0.5846\n",
      "Epoch 187/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9877Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4868 - acc: 0.5808\n",
      "Epoch 00187: saving model to /home/team2/fishgo/training/models/model_ex-187_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 736ms/step - loss: 0.0557 - acc: 0.9879 - val_loss: 2.4868 - val_acc: 0.5808\n",
      "Epoch 188/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9906Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4956 - acc: 0.5808\n",
      "Epoch 00188: saving model to /home/team2/fishgo/training/models/model_ex-188_acc-0.580769.h5\n",
      "108/108 [==============================] - 80s 737ms/step - loss: 0.0451 - acc: 0.9907 - val_loss: 2.4956 - val_acc: 0.5808\n",
      "Epoch 189/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9859Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4825 - acc: 0.5885\n",
      "Epoch 00189: saving model to /home/team2/fishgo/training/models/model_ex-189_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0500 - acc: 0.9860 - val_loss: 2.4825 - val_acc: 0.5885\n",
      "Epoch 190/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9859Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4822 - acc: 0.5885\n",
      "Epoch 00190: saving model to /home/team2/fishgo/training/models/model_ex-190_acc-0.588462.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0486 - acc: 0.9851 - val_loss: 2.4822 - val_acc: 0.5885\n",
      "Epoch 191/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9840Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4799 - acc: 0.5846\n",
      "Epoch 00191: saving model to /home/team2/fishgo/training/models/model_ex-191_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.0567 - acc: 0.9841 - val_loss: 2.4799 - val_acc: 0.5846\n",
      "Epoch 192/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9896Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4778 - acc: 0.5923\n",
      "Epoch 00192: saving model to /home/team2/fishgo/training/models/model_ex-192_acc-0.592308.h5\n",
      "108/108 [==============================] - 80s 738ms/step - loss: 0.0415 - acc: 0.9897 - val_loss: 2.4778 - val_acc: 0.5923\n",
      "Epoch 193/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9791Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4937 - acc: 0.5846\n",
      "Epoch 00193: saving model to /home/team2/fishgo/training/models/model_ex-193_acc-0.584615.h5\n",
      "108/108 [==============================] - 79s 731ms/step - loss: 0.0576 - acc: 0.9793 - val_loss: 2.4937 - val_acc: 0.5846\n",
      "Epoch 194/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9860Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4907 - acc: 0.5846\n",
      "Epoch 00194: saving model to /home/team2/fishgo/training/models/model_ex-194_acc-0.584615.h5\n",
      "108/108 [==============================] - 80s 740ms/step - loss: 0.0429 - acc: 0.9861 - val_loss: 2.4907 - val_acc: 0.5846\n",
      "Epoch 195/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9906Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4861 - acc: 0.5885\n",
      "Epoch 00195: saving model to /home/team2/fishgo/training/models/model_ex-195_acc-0.588462.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.0415 - acc: 0.9897 - val_loss: 2.4861 - val_acc: 0.5885\n",
      "Epoch 196/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9906Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4927 - acc: 0.5808\n",
      "Epoch 00196: saving model to /home/team2/fishgo/training/models/model_ex-196_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0520 - acc: 0.9897 - val_loss: 2.4927 - val_acc: 0.5808\n",
      "Epoch 197/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9840Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4879 - acc: 0.5923\n",
      "Epoch 00197: saving model to /home/team2/fishgo/training/models/model_ex-197_acc-0.592308.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0677 - acc: 0.9841 - val_loss: 2.4879 - val_acc: 0.5923\n",
      "Epoch 198/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9877Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4766 - acc: 0.5808\n",
      "Epoch 00198: saving model to /home/team2/fishgo/training/models/model_ex-198_acc-0.580769.h5\n",
      "108/108 [==============================] - 79s 734ms/step - loss: 0.0486 - acc: 0.9879 - val_loss: 2.4766 - val_acc: 0.5808\n",
      "Epoch 199/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9925Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.5003 - acc: 0.5808\n",
      "Epoch 00199: saving model to /home/team2/fishgo/training/models/model_ex-199_acc-0.580769.h5\n",
      "108/108 [==============================] - 80s 736ms/step - loss: 0.0487 - acc: 0.9925 - val_loss: 2.5003 - val_acc: 0.5808\n",
      "Epoch 200/200\n",
      "107/108 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9859Epoch 1/200\n",
      " 26/108 [======>.......................] - ETA: 10s - loss: 2.4893 - acc: 0.5923\n",
      "Epoch 00200: saving model to /home/team2/fishgo/training/models/model_ex-200_acc-0.592308.h5\n",
      "108/108 [==============================] - 79s 735ms/step - loss: 0.0742 - acc: 0.9860 - val_loss: 2.4893 - val_acc: 0.5923\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = '/home/team2/fishgo/training'\n",
    "model_trainer = ModelTraining()\n",
    "model_trainer.setModelTypeAsResNet()\n",
    "model_trainer.setDataDirectory(DATASET_DIR)\n",
    "model_trainer.trainModel(num_objects=21, num_experiments=200, enhance_data=True, batch_size=10, show_network_summary=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
